{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3880779,"sourceType":"datasetVersion","datasetId":2306175}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow kaggle pillow matplotlib tensorflowjs keras-tuner","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport random\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nimport tensorflowjs as tfjs\nfrom keras_tuner import RandomSearch, Hyperband, BayesianOptimization\n\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n\ntrain_directory = \"/kaggle/input/nepali-food-images/dataset/train\"\ntest_directory = \"/kaggle/input/nepali-food-images/dataset/test\"\n\nbatch_size, img_width, img_height = 32, 224, 224","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def count_files_and_images(dir):\n    class_count = {}\n    total = 0\n    for class_name in os.listdir(dir):\n        path = os.path.join(dir, class_name)\n        if os.path.isdir(path):\n            file_count = len(os.listdir(path))\n            class_count[class_name] = file_count\n            total += file_count\n    return class_count, total","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_class_count, train_total = count_files_and_images(train_directory)\ntest_class_count, test_total = count_files_and_images(test_directory)\n\nprint(\"Train class count: \", train_class_count)\nprint(\"Train total: \", train_total)\n\nprint(\"Test class count: \", test_class_count)\nprint(\"Test total: \", test_total)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = tf.keras.utils.image_dataset_from_directory(\n    train_directory,\n    shuffle=True,\n    batch_size=batch_size,\n    labels=\"inferred\",\n)\ntest_dataset = tf.keras.utils.image_dataset_from_directory(\n    test_directory,\n    batch_size=batch_size,\n    labels=\"inferred\",\n)\nclass_names = train_dataset.class_names\nprint(\"Class names: \", class_names)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor images, labels in train_dataset.take(1):\n    for i in range(9):\n        plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(train_dataset.class_names[labels[i]])\n        plt.axis(\"off\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = train_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n\ntest_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_history(history):\n  acc = history.history['accuracy']\n  val_acc = history.history['val_accuracy']\n\n  loss = history.history['loss']\n  val_loss = history.history['val_loss']\n\n  epochs_range = range(len(loss))\n\n  plt.figure(figsize=(8, 8))\n  plt.subplot(1, 2, 1)\n  plt.plot(epochs_range, acc, label='Training Accuracy')\n  plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n  plt.legend(loc='lower right')\n  plt.title('Training and Validation Accuracy')\n\n  plt.subplot(1, 2, 2)\n  plt.plot(epochs_range, loss, label='Training Loss')\n  plt.plot(epochs_range, val_loss, label='Validation Loss')\n  plt.legend(loc='upper right')\n  plt.title('Training and Validation Loss')\n  plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def fit_model(model, epochs, model_name):\n  history = model.fit(train_dataset,\n                        validation_data=test_dataset,\n                        epochs=epochs,\n                        callbacks=[\n                            ModelCheckpoint(\n                                filepath=f'/kaggle/temp/weights/{model_name}',\n                                save_weights_only=True,\n                                verbose=1,\n                                save_freq='epoch',\n                                period=20),\n                            EarlyStopping(\n                                monitor='val_loss', \n                                min_delta=0.001, \n                                patience=10, \n                                mode='min', \n                                restore_best_weights=True\n                            )\n                        ])\n  # Save the model in the Keras format\n  model_path = f'/kaggle/working/saved/{model_name}.keras'\n  model.save(model_path, overwrite=True, save_format=\"keras\")\n  print(f\"Model saved to {model_path}\")\n\n  # Convert the Keras model to TensorFlow.js format\n  tfjs_target_dir = f'/kaggle/working/saved/{model_name}_tfjs'\n  tfjs.converters.save_keras_model(model, tfjs_target_dir)\n  print(f\"Model converted to TensorFlow.js format and saved to {tfjs_target_dir}\")\n\n  model.summary()\n  show_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def simple_multilayer_model():\n    model = Sequential([\n      layers.Resizing(img_width, img_height),\n      layers.Rescaling(1./255,input_shape=(180, 180, 3)),\n      layers.Flatten(),\n      layers.Dense(2000, activation='relu'),\n      layers.Dense(1000, activation='relu'),\n      layers.Dense(500, activation='relu'),\n      layers.Dense(128, activation='relu'),\n      layers.Dense(len(class_names), name=\"outputs\")\n    ])\n\n    model.compile(\n        optimizer=\"adam\",\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        metrics=[\"accuracy\"],\n    )\n\n    epochs = 100\n    fit_model(model, epochs, 'simple_multilayer')\n\nsimple_multilayer_model()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def augmented_multilayer_model():\n    model = Sequential([\n      layers.Resizing(img_width, img_height),\n      layers.Rescaling(1./255),\n      layers.RandomFlip(),\n      layers.RandomRotation(.2),\n      layers.RandomZoom(.2),\n      layers.Flatten(),\n      layers.Dense(2000, activation='relu'),\n      layers.Dense(1000, activation='relu'),\n      layers.Dropout(0.25),\n      layers.Dense(500, activation='relu'),\n      layers.Dropout(0.2),\n      layers.Dense(128, activation='relu'),\n      layers.Dropout(0.05),\n      layers.Dense(len(class_names), name=\"outputs\")\n    ])\n\n    model.compile(\n        optimizer=\"adam\",\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        metrics=[\"accuracy\"],\n    )\n    epochs = 100\n    fit_model(model, epochs, 'augmented_multilayer')\n\naugmented_multilayer_model()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def augmented_conv_model():\n    model = Sequential([\n      layers.Resizing(img_width, img_height),\n      layers.Rescaling(1./255),\n      layers.RandomFlip(),\n      layers.RandomRotation(.2),\n      layers.RandomZoom(.2),\n      layers.Conv2D(16, 3, padding='same', activation='relu'),\n      layers.MaxPooling2D(),\n      layers.Conv2D(32, 3, padding='same', activation='relu'),\n      layers.MaxPooling2D(),\n      layers.Conv2D(64, 3, padding='same', activation='relu'),\n      layers.MaxPooling2D(),\n      layers.Flatten(),\n      layers.Dense(512, activation='relu'),\n      layers.Dropout(0.2),\n      layers.Dense(128, activation='relu'),\n      layers.Dense(len(class_names), name=\"outputs\")\n    ])\n\n    model.compile(\n        optimizer=\"adam\",\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        metrics=[\"accuracy\"],\n    )\n    epochs = 100\n    fit_model(model, epochs, 'augmented_conv')\n\naugmented_conv_model()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def augmented_conv_model_v2():\n    model = Sequential([\n      layers.Resizing(img_width, img_height),\n      layers.Rescaling(1./255),\n      layers.RandomFlip(),\n      layers.RandomRotation(.1),\n      layers.RandomZoom(.1),\n      layers.RandomTranslation(0.1, 0.1),\n      layers.RandomContrast(0.1),\n      layers.Conv2D(32, 3, padding='same', activation='relu'),\n      layers.BatchNormalization(),\n      layers.MaxPooling2D(),\n      layers.Conv2D(64, 3, padding='same', activation='relu'),\n      layers.BatchNormalization(),\n      layers.MaxPooling2D(),\n      layers.Conv2D(128, 3, padding='same', activation='relu'),\n      layers.MaxPooling2D(),\n      layers.Flatten(),\n      layers.Dense(64, activation='relu'),\n      layers.Dropout(0.05),\n      layers.Dense(len(class_names), name=\"outputs\")\n    ])\n\n    model.compile(\n        optimizer=\"adam\",\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n        metrics=[\"accuracy\"],\n    )\n    epochs = 100\n    fit_model(model, epochs, 'augmented_conv')\n\naugmented_conv_model_v2()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def hyper_parameter_optimized_augmented_conv_model():\n    def build_model(hp):\n        model = keras.Sequential([\n            layers.Resizing(img_width, img_height),\n            layers.Rescaling(1./255),\n            layers.RandomFlip(),\n            layers.RandomRotation(0.1),\n            layers.RandomZoom(0.1),\n            layers.RandomTranslation(0.1, 0.1),\n            layers.RandomContrast(0.1),\n            layers.Conv2D(\n                filters=hp.Int('conv_1_filters', min_value=32, max_value=128, step=32),\n                kernel_size=3,\n                padding='same',\n                activation='relu'\n            ),\n            layers.BatchNormalization(),\n            layers.MaxPooling2D(),\n            layers.Conv2D(\n                filters=hp.Int('conv_2_filters', min_value=64, max_value=256, step=32),\n                kernel_size=3,\n                padding='same',\n                activation='relu'\n            ),\n            layers.BatchNormalization(),\n            layers.MaxPooling2D(),\n            layers.Conv2D(\n                filters=hp.Int('conv_3_filters', min_value=128, max_value=512, step=32),\n                kernel_size=3,\n                padding='same',\n                activation='relu'\n            ),\n            layers.MaxPooling2D(),\n            layers.Flatten(),\n            layers.Dense(\n                units=hp.Int('dense_units', min_value=32, max_value=128, step=32),\n                activation='relu'\n            ),\n            layers.Dropout(hp.Float('dropout', min_value=0.0, max_value=0.5, default=0.25, step=0.01)),\n            layers.Dense(len(class_names), name=\"outputs\")\n        ])\n\n        model.compile(\n            optimizer=keras.optimizers.Adam(\n                hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')\n            ),\n            loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n            metrics=['accuracy']\n        )\n\n        return model\n\n    tuner = Hyperband(\n        build_model,\n        objective='val_accuracy',\n        max_epochs=10,\n        factor=3,\n        directory='tuning',\n        project_name='image_classification_tuning'\n    )\n    \n    tuner.search(train_dataset, epochs=10, validation_data=test_dataset)\n    print(\"found\")\n    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n    print(best_hps)\n    # Build the model with the optimal hyperparameters and train it on the data\n    model = tuner.hypermodel.build(best_hps)\n    \n    epochs = 100\n    fit_model(model, epochs, 'augmented_conv')\n\nhyper_parameter_optimized_augmented_conv_model()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.models import Model\n\ndef fine_tune_efficient_net():\n    # Load the pre-trained model, excluding the top layer\n    base_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n\n    # Freeze the layers of the base model\n    for layer in base_model.layers:\n        layer.trainable = False\n    \n    # Add our new input layer and output layer to the base model\n    model = Sequential([\n        layers.InputLayer(input_shape=(None, None, 3)),\n        layers.Resizing(224, 224),\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dense(len(class_names), activation='softmax')\n    ])\n    \n    epochs = 10\n    model.compile(\n        optimizer=\"adam\",\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n        metrics=[\"accuracy\"],\n    )\n    fit_model(model, epochs, 'efficient_net_finetune')\n\nfine_tune_efficient_net()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!rm -rf /kaggle/working/saved/efficient_net_finetune_tfjs\n!pip install numpy==1.22.4","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r /kaggle/working/saved/efficient_net_finetune_tfjs.zip /kaggle/working/saved/efficient_net_finetune_tfjs","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}