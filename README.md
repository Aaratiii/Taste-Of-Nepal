[DatabaseURL]=mongodb+srv://aaratikharel076:hqKTCO2BXg61XjVr@cluster0.dxqrftg.mongodb.net/

Taste of Nepal - Machine Learning Approach

The Taste of Nepal web application incorporates Machine Learning to classify food images, utilizing Multilayer Perceptron (MLP) and Convolutional Neural Networks (CNNs). Initially, MLP was implemented for classification, but its accuracy was relatively low due to its inability to capture spatial patterns in images effectively. To enhance performance, the approach was shifted towards CNNs, which achieved a classification accuracy of 70%. CNN employs convolutional layers to extract key image features, pooling layers to reduce dimensionality while retaining essential patterns, and fully connected layers for classification. The Hyperband tuning algorithm was applied to optimize hyperparameters, allowing the system to determine the best configuration for classifying images into specific food categories.

ML Workflow and Algorithm Performance
The classifier was trained using a dataset sourced from Kaggle, ensuring diversity in food categories. The dataset underwent preprocessing steps, including resizing images to a fixed format, normalizing pixel values to a standard range, and structuring data appropriately for CNN input. The training process involved backpropagation and gradient descent to minimize prediction errors. The dataset was divided into training and validation sets, ensuring that the model could generalize well to unseen data. The Hyperband tuning algorithm was leveraged to fine-tune hyperparameters, optimizing model efficiency and accuracy.

The result analysis demonstrated a consistent upward trend in accuracy across training epochs. Initially, both training and validation accuracies were low, but with continued training, they improved significantly. The CNN model outperformed MLP, providing a more reliable and generalizable classification system. The graphical representation of training accuracy (blue) and validation accuracy (orange) showed convergence without significant overfitting, reinforcing the model’s reliability.

Result Analysis
Testing of the system confirmed the successful integration of the machine learning classifier with the food recipe platform. The classifier accurately recognized food images, retrieved corresponding names, and provided historical data. The testing phase validated that the CNN-based classifier was capable of distinguishing food categories effectively, improving the overall user experience. Apart from the classifier, other core functionalities, including recipe submission, approval, and the user notification system, were tested and found to operate seamlessly. The classifier’s ability to generalize well to unseen food images highlights its robustness and adaptability.

Conclusion
The integration of image classification technology into a food recipe platform enhances the user experience by providing a dynamic and interactive system. The CNN-based approach significantly improves classification accuracy compared to traditional MLP networks. The model demonstrates strong generalization, ensuring effective food recognition while maintaining a streamlined and efficient classification pipeline. By combining machine learning with culinary exploration, the platform offers a unique and engaging way for users to discover and interact with diverse food items.

Future Enhancements
While the system performs well, there is potential for further enhancements. Expanding the dataset with more diverse and regionally distinct food images would improve classification accuracy. Integrating personalized user experiences, such as recommending recipes based on user preferences, would add value to the platform. Multilingual support could make the application more accessible to a global audience. Implementing a continuous training pipeline would allow the model to adapt to evolving food trends and user-submitted images. Further fine-tuning of the classifier to recognize cultural variations in food presentation could enhance its ability to distinguish between similar dishes. Additionally, incorporating multimodal capabilities by integrating image recognition with contextual data such as ingredients and cooking methods would further enrich the user experience.
